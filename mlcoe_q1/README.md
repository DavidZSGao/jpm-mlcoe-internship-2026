# Question 1 — Balance Sheet Forecasting

This package contains code and assets for the lending application prototype described in Question 1.

## Layout
- `data/` — raw downloads and intermediate feature sets for financial statements.
- `models/` — TensorFlow models and supporting modules for balance-sheet simulation.
- `pipelines/` — end-to-end training and evaluation workflows.
- `experiments/` — scripts and notebooks for reproducible experimentation.
- `evaluation/` — metrics, diagnostics, and reporting utilities.
- `utils/` — shared helpers (I/O, accounting identities, feature engineering).

Tests for this module live under `tests/q1`.

Refer to `reports/q1/q1_response_summary.md` for a consolidated mapping between the revised Question 1 prompt and the implemented pipelines, and see `reports/q1/strategic_lending_playbook.md` for a field guide that strings the pipelines into repeatable refresh runs.

## Usage
- `python -m mlcoe_q1.pipelines.download_statements TICKER ...` downloads or loads cached statements into `data/raw/` (pass `--cache-only` to force offline mode).
- `python -m mlcoe_q1.pipelines.prepare_processed_data [TICKER ...]` converts cached bundles into parquet tables under `data/processed/`.
- `python -m mlcoe_q1.pipelines.build_driver_dataset [--tickers ... --lags 2 --lag-features sales sales_growth]` derives forecasting driver ratios with log-revenue and per-asset normalisation, now including tangible-equity, interest-spread, and year-over-year growth metrics for banks and corporates, and can append lagged histories before writing `driver_features.parquet`. Provide `--config configs/q1/build_driver_dataset.json` to reuse the repository defaults without retyping paths or lag selections.
- `python -m mlcoe_q1.pipelines.train_forecaster` trains an MLP on driver progression with a bank-aware output head, exports bank templates from `data/processed/`, and saves artifacts under `models/artifacts/` (override data location with `--processed-root`). Pass `--calibrate-banks` to fit ensemble weights after training, enable the probabilistic head via `--distribution gaussian` to learn mean/log-variance forecasts, explore `--distribution variational --kl-weight 1e-3` for KL-regularised driver uncertainty, and switch to a sequential architecture with `--architecture gru --sequence-length 4 --gru-units 64,64` when experimenting with recurrent extensions. The preset `--config configs/q1/train_forecaster.json` mirrors the Strategic Lending defaults for quick restarts.
- `python -m mlcoe_q1.pipelines.evaluate_forecaster --bank-mode {auto,template,mlp,persistence,ensemble}` backtests the saved model; `auto` prefers the calibrated ensemble when available and falls back to template/MLP/persistence strategies as needed. Add `--mc-samples 100` (optionally with `--quantiles 0.1,0.5,0.9`) to quantify predictive intervals via Monte Carlo dropout or draw samples from the learned Gaussian/variational heads when those distributions are enabled, and use `--horizon 4` to roll projections forward multiple periods with recursive identity checks. Supply `--config configs/q1/evaluate_forecaster.json` to reuse the curated evaluation defaults (paths, Monte Carlo samples, horizon) shared across orchestration presets.
- `python -m mlcoe_q1.pipelines.calibrate_bank_ensemble` recomputes the linear ensemble weights that blend bank templates with neural projections, updating `bank_ensemble.json` alongside the model artifacts.
- `python -m mlcoe_q1.pipelines.summarize_forecaster_evaluation [--group-by ticker,mode]` aggregates the evaluation parquet into grouped MAE/identity-gap statistics, reports interval widths/coverage when Monte Carlo quantiles are present, and persists the summary parquet with `--output`.
- `python -m mlcoe_q1.pipelines.package_scenarios --scenarios baseline:0.5,downside:0.1,upside:0.9` reshapes Monte Carlo quantiles into Strategic Lending scenarios (baseline, downside, upside by default) with point-estimate fallbacks when quantiles are unavailable, saving `forecaster_scenarios.parquet`. Provide `--config configs/q1/package_scenarios.json` to reuse the repository defaults without retyping paths or scenario definitions.
- `python -m mlcoe_q1.pipelines.simulate_macro_conditions [--scenarios macro_scenarios.json]` layers macro-driven shocks onto the packaged scenarios, appending consensus/mild-downturn/rate-shock cases by default and writing `macro_conditioned_scenarios.parquet` with macro metadata and adjustment provenance for each borrower. Use `--config configs/q1/simulate_macro_conditions.json` for a ready-made setup referencing the included macro scenario template.
- `python -m mlcoe_q1.pipelines.analyze_forecaster_calibration [--group-by ticker,mode --metrics assets,equity]` compares empirical quantile coverage against requested Monte Carlo targets to highlight variance calibration issues by ticker, horizon, or forecasting mode. Apply `--config configs/q1/analyze_forecaster_calibration.json` to load the standard grouping/metric mix before overriding on the CLI.
- `python -m mlcoe_q1.pipelines.assess_scenario_reasonableness --interval-lower downside --interval-upper upside` scores packaged scenarios against realised filings, reporting MAE/MAPE, interval coverage, and average widths per scenario or grouping column; `--config configs/q1/assess_scenario_reasonableness.json` preloads the baseline/downside/upside conventions used across the orchestration workflow.
- `python -m mlcoe_q1.pipelines.generate_lending_briefing` renders a Strategic Lending Markdown briefing with Monte Carlo coverage warnings, falling back to the evaluation parquet when a pre-computed summary is unavailable; supply `--config configs/q1/generate_lending_briefing.json` to reuse repository paths for the summary/evaluation artifacts.
- `python -m mlcoe_q1.pipelines.generate_executive_summary [--output reports/q1/status/executive_summary.md]` consolidates evaluation summaries, scenario diagnostics, macro overlays, LLM benchmarking variance, loan pricing, credit metadata, and risk warnings into an executive-ready Markdown memo. Use `--config configs/q1/generate_executive_summary.json` for the house defaults, then override individual artifacts as needed.
- `python -m mlcoe_q1.pipelines.compile_lending_package [--copy-artifacts]` collects the briefing, scenario tables, macro overlays, calibration diagnostics, and credit analytics into a single deliverable directory with a JSON manifest and Markdown index, optionally copying the inputs for offline review; reuse `--config configs/q1/compile_lending_package.json` to toggle copying and output directories via JSON.
- `python -m mlcoe_q1.pipelines.audit_lending_artifacts [--output reports/q1/status/lending_artifact_audit.json]` audits the Strategic Lending artifact suite, flagging missing required deliverables and emitting both JSON and Markdown summaries for governance checkpoints (customise the expectation list via `--config`).
- `python -m mlcoe_q1.pipelines.orchestrate_lending_workflow [--scenario-spec baseline:0.5,downside:0.1,upside:0.9]` stitches together summarisation, scenario packaging, macro overlays, calibration, briefing generation, and deliverable packaging so Strategic Lending analysts can refresh the entire artifact suite with a single command. Provide `--config configs/q1/orchestrate_lending_workflow.json` to reuse the repository defaults without retyping every path.
- `python -m mlcoe_q1.pipelines.publish_lending_submission [--zip-output reports/q1/deliverables/strategic_lending.zip]` runs the orchestrator, regenerates the executive summary, audits required artifacts, and optionally zips the deliverable directory so the full Strategic Lending submission (summaries, scenarios, macro overlays, calibration, pricing, credit, risk) ships as a governance-ready bundle in one command.
- `python -m mlcoe_q1.pipelines.publish_lending_submission --config configs/q1/publish_lending_submission.json` consumes the provided JSON defaults, including macro overlays, audit expectations, artifact copying, and bundle locations; CLI flags can still override specific settings for ad-hoc runs.
- `python -m mlcoe_q1.pipelines.price_loans artifacts/forecaster_scenarios.parquet --credit-dataset data/credit_ratings/altman_features.parquet --macro-sensitivity configs/q1/loan_pricing_macro.json` combines packaged scenarios with Altman-derived ratings and optional macro-conditioned sensitivities to produce lender-ready loan pricing tables with decomposed spreads, macro adjustments, indicator-level macro columns, and summary JSON alongside optional parquet outputs. Provide `--config configs/q1/price_loans.json` to preconfigure the standard Strategic Lending artifacts and summary destinations.
- `python -m mlcoe_q1.pipelines.report_forecaster_status [--group-by ticker mode]` renders the summarised MAE/identity-gap/net-income metrics into a Markdown status report, optionally writing to disk via `--output`.
- `python -m mlcoe_q1.pipelines.build_llm_prompt_dataset [--statements balance_sheet income_statement]` creates prompt/label pairs for Part 2 LLM experiments by pairing prior-period statements with ground-truth targets; persistable via `--output`.
- `python -m mlcoe_q1.pipelines.run_llm_adapter --prompts ... --adapter flan-t5 --model t5-small` invokes a HuggingFace text-to-text model to generate JSON forecasts for the prompt corpus with automatic truncation of overlong inputs; use `--limit` for sampling smaller batches during development. Switch to `--adapter hf-causal --model distilgpt2` (or another causal checkpoint) to exercise decoder-only LLMs with automatic pad-token handling, pass comma-separated models via `--model model-a,model-b`, use `--seeds 1,2,3` to sweep generation randomness, and call hosted APIs via `--adapter openai-chat --model gpt-4o-mini --api-key-env CUSTOM_KEY --api-base https://...` when benchmarking GPT-4o/Claude-compatible endpoints. Each run now emits a `<output>.metadata.json` sidecar capturing adapter/model/seed parameters, API provenance, and record counts for governance reviews. Provide `--config configs/q1/run_llm_adapter.json` to preload common adapter/model/path settings while allowing CLI overrides for ad-hoc experiments.
- `python -m mlcoe_q1.pipelines.benchmark_llm_suite --prompts ... --output-root artifacts/llm_bench --adapter openai-chat --models gpt-4o-mini,gpt-4.1 --seeds 1,2,3` orchestrates multi-model, multi-seed sweeps, captures raw responses/metrics, and emits per-seed summaries plus a `summary_by_model.parquet` table with standard deviations/seed counts so hosted and local adapters share a common evaluation workflow with documented variance. Use `--config configs/q1/benchmark_llm_suite.json` to reuse prompt/model/seed presets and artifact destinations without duplicating long command lines.
- `python -m mlcoe_q1.pipelines.summarize_llm_benchmarks --manifest artifacts/llm_bench/manifest.json --output artifacts/llm_bench/benchmark_ranked.parquet --markdown-output reports/q1/status/llm_benchmark_summary.md` ranks the aggregated benchmark metrics, appends MAE/MAPE/coverage-based ordering, and generates a Markdown briefing that highlights the top-performing configurations and lowest-variance seeds for governance review. Preset configs can be supplied via `--config configs/q1/summarize_llm_benchmarks.json` (CLI flags still override individual paths/limits).
- `python -m mlcoe_q1.pipelines.generate_llm_baseline_responses --prompt-dataset ... --strategy {context_copy,scaled_copy}` still ships as a deterministic baseline for comparison.
- `python -m mlcoe_q1.pipelines.evaluate_llm_responses --prompt-dataset ... --responses ...` scores JSON responses from LLMs against the prompt dataset, computing coverage, MAE/MAPE, and exportable per-record metrics with `--output`.
- `python -m mlcoe_q1.pipelines.compare_llm_and_forecaster --forecaster-eval ... --llm-metrics ...` joins the structured evaluation artifact with LLM metrics on matching ticker/period slices, prints grouped summaries (default by ticker), and can persist both the merged table (`--output`) and aggregate statistics (`--summary-output`).
- `python -m mlcoe_q1.pipelines.generate_cfo_recommendations --forecaster-eval ... --llm-eval ...` renders Markdown guidance for CFOs/CEOs by combining structured MAE metrics with LLM coverage diagnostics; the preset `--config configs/q1/generate_cfo_recommendations.json` points at the standard evaluation artifacts and headline count.
- `python -m mlcoe_q1.pipelines.summarize_workplan_progress --workplan reports/q1/q1_workplan.md --output reports/q1/status/workplan_progress.md` parses the execution plan checkboxes, reports completed vs. remaining counts per section, and can also emit JSON metadata via `--json-output` (both destinations are pre-wired in `configs/q1/summarize_workplan_progress.json`).
- `python -m mlcoe_q1.pipelines.validate_driver_dataset [--min-observations 3 --max-gap-days 500]` inspects the driver dataset for duplicate periods, feature gaps, long filing intervals, and can persist the validation report with `--output`.
- `python -m mlcoe_q1.pipelines.extract_pdf_ratios --company {gm,lvmh,tencent,alibaba,jpm,exxon,microsoft,vw,alphabet,google,mercedes,sap,toyota,nestle,hsbc,santander} PATH/TO/REPORT.pdf` extracts ratios directly from the PDF and records provenance metadata; pass `--config` with a JSON override to support additional layouts.
- `python -m mlcoe_q1.pipelines.build_credit_rating_dataset [--tickers ... --min-year 2019]` assembles Altman-style features from Yahoo Finance balance sheets/income statements (including the Evergrande `3333.HK` ticker by default), saving `altman_features.parquet` plus JSON metadata documenting ticker coverage.
- `python -m mlcoe_q1.pipelines.score_credit_rating --ticker 3333.HK --period 2022-12-31` scores a single filing period via the generated dataset; use `--metrics-file annual_report_metrics.json` to provide manual inputs from an extracted annual report and emit the Altman Z-score/rating bucket for issuers without Yahoo Finance coverage.
- `python -m mlcoe_q1.pipelines.extract_risk_warnings --input text_chunks.jsonl` scans structured PDF/HTML text chunks for risk-factor disclosures,
  classifies them into going-concern, liquidity, regulatory, and operational buckets, and writes both a detailed parquet and issuer/category summary for Strategic Lending triage; reuse output destinations with `--config` while still overriding the per-run input file.

## Notes
- The downloader falls back to Yahoo's fundamentals-timeseries API when `yfinance` yields empty frames, so direct HTTP access is required on first fetch.
- `mlcoe_q1/models/balance_sheet_constraints.py` provides deterministic identity-preserving projections that map driver vectors to full statements.
- Processed data and drivers currently cover a nine-ticker mix of cyclicals/industrials (GM, HON, CAT, UNP), large-cap comparables (AAPL, MSFT), and banks (JPM, BAC, C) for sector-aware training experiments, with bank rows now capturing net-interest, gross-interest, and tangible-equity ratios alongside the shared corporate features.
- The TensorFlow forecaster blends a shared corporate head with a dedicated bank head controlled by the `is_bank` auxiliary feature so financial institutions can specialise without retraining a separate network, and now supports a Gaussian output head for probabilistic driver forecasts.
- See `reports/q1/deterministic_balance_sheet_spec.md` for the mathematical walkthrough of the projection engine and its simulation framing.
- Earnings coverage and next steps are documented in `reports/q1/notes/earnings_linkage.md`.
- Model extension priorities and probabilistic roadmap live in `reports/q1/notes/ml_extension_roadmap.md`.
- Simulation framing and exogenous driver assumptions are detailed in `reports/q1/notes/simulation_strategy.md`.
- Literature highlights from Vélez-Pareja, Mejía-Pelaez, Shahnazarian, and Samonas are summarised in `reports/q1/literature_summary.md` with implementation takeaways for this codebase.
- HuggingFace adapters rely on the CPU `torch` build plus `transformers`/`sentencepiece`; install via `pip install -r requirements.txt` and expect the first inference run to download ~200 MB of weights. Decoder-only checkpoints (via `--adapter hf-causal`) automatically configure pad tokens for causal generation.
- The PDF ratio extractor depends on `pdfplumber>=0.11.0`; install with `pip install -r requirements.txt` before running the CLI. Built-in presets now cover GM, LVMH, Tencent, Alibaba, JPMorgan Chase, ExxonMobil, Microsoft, Volkswagen, Alphabet/Google, Mercedes-Benz Group, SAP, Toyota, Nestlé, HSBC, and Banco Santander with ratio fallbacks when current/quick metrics are unavailable.
