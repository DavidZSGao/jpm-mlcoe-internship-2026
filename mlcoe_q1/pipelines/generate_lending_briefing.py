"""Generate a Strategic Lending briefing from forecaster summary metrics."""

from __future__ import annotations

import argparse
import logging
from pathlib import Path
from typing import Iterable, Sequence

import pandas as pd

from mlcoe_q1.pipelines.summarize_forecaster_evaluation import (
    summarize as summarize_metrics,
)
from mlcoe_q1.utils.config import add_config_argument, parse_args_with_config


DEFAULT_SUMMARY = (
    Path(__file__).resolve().parents[2]
    / "reports/q1/artifacts/forecaster_evaluation_summary.parquet"
)
DEFAULT_EVALUATION = (
    Path(__file__).resolve().parents[2]
    / "reports/q1/artifacts/forecaster_evaluation.parquet"
)
DEFAULT_OUTPUT = (
    Path(__file__).resolve().parents[2]
    / "reports/q1/status/strategic_lending_briefing.md"
)


def parse_args(argv: Sequence[str] | None = None) -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    add_config_argument(parser)
    parser.add_argument(
        "--summary",
        type=Path,
        default=DEFAULT_SUMMARY,
        help="Path to the aggregated summary parquet produced by summarize_forecaster_evaluation",
    )
    parser.add_argument(
        "--evaluation",
        type=Path,
        default=DEFAULT_EVALUATION,
        help=(
            "Fallback evaluation parquet generated by evaluate_forecaster. "
            "Used when --summary is unavailable."
        ),
    )
    parser.add_argument(
        "--group-by",
        type=str,
        default="ticker,mode",
        help="Comma separated list of columns used when summarising the evaluation parquet",
    )
    parser.add_argument(
        "--coverage-target",
        type=float,
        default=0.9,
        help="Desired Monte Carlo coverage target used for flagging shortfalls",
    )
    parser.add_argument(
        "--identity-threshold",
        type=float,
        default=5e8,
        help="Absolute accounting identity gap threshold (in currency units) for warnings",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=DEFAULT_OUTPUT,
        help="Destination path for the generated Markdown briefing",
    )
    parser.add_argument("--log-level", default="INFO")
    return parse_args_with_config(
        parser,
        argv,
        type_overrides={
            "summary": Path,
            "evaluation": Path,
            "output": Path,
        },
    )


def _parse_group_columns(raw: str) -> list[str]:
    if not raw.strip():
        return []
    return [token.strip() for token in raw.split(",") if token.strip()]


def _format_billions(value: float | int | None) -> str:
    if value is None or pd.isna(value):
        return "NA"
    return f"${float(value) / 1e9:.2f}B"


def _column_labels(prefix: str) -> tuple[str, str]:
    base = prefix.replace("_", " ")
    return base.title(), prefix


def _coverage_columns(columns: Iterable[str]) -> dict[str, str]:
    mapping: dict[str, str] = {}
    for column in columns:
        if column.endswith("_interval_coverage"):
            pretty = column[: -len("_interval_coverage")].replace("_", " ").title()
            mapping[column] = pretty
    return mapping


def _width_columns(columns: Iterable[str]) -> dict[str, str]:
    mapping: dict[str, str] = {}
    for column in columns:
        if column.endswith("_interval_width_mean"):
            pretty = column[: -len("_interval_width_mean")].replace("_", " ").title()
            mapping[column] = pretty
    return mapping


def _format_identifier(row: pd.Series, group_cols: Sequence[str]) -> str:
    if not group_cols:
        return "Aggregate"
    parts = []
    for col in group_cols:
        if col in row:
            parts.append(str(row[col]))
    return " - ".join(parts) if parts else "Aggregate"


def build_briefing(
    summary: pd.DataFrame,
    group_cols: Sequence[str],
    coverage_target: float,
    identity_threshold: float,
) -> str:
    if summary.empty:
        raise ValueError("Summary dataframe is empty; run summarize_forecaster_evaluation first")

    if not 0.0 <= coverage_target <= 1.0:
        raise ValueError("Coverage target must fall within [0, 1]")

    summary = summary.copy()
    coverage_cols = _coverage_columns(summary.columns)
    width_cols = _width_columns(summary.columns)

    metric_columns = []
    for column in ["observations", "assets_mae_mean", "equity_mae_mean", "identity_gap_mean"]:
        if column in summary.columns:
            metric_columns.append(column)
    if "net_income_mae_mean" in summary.columns:
        metric_columns.append("net_income_mae_mean")
    metric_columns.extend(width_cols)
    metric_columns.extend(coverage_cols)

    display_df = summary[metric_columns].copy()
    rename_map = {
        "observations": "Observations",
        "assets_mae_mean": "Assets MAE",
        "equity_mae_mean": "Equity MAE",
        "identity_gap_mean": "Identity Gap",
        "net_income_mae_mean": "Net Income MAE",
    }
    for column, label in width_cols.items():
        rename_map[column] = f"{label} Interval Width"
    for column, label in coverage_cols.items():
        rename_map[column] = f"{label} Coverage"
    display_df = display_df.rename(columns=rename_map)

    monetary_columns = [
        name
        for name in display_df.columns
        if any(keyword in name for keyword in ["MAE", "Identity", "Width"])
    ]
    for column in monetary_columns:
        display_df[column] = display_df[column].apply(_format_billions)

    identifier_cols = [col for col in group_cols if col in summary.columns]
    if identifier_cols:
        display_df = pd.concat([summary[identifier_cols], display_df], axis=1)

    try:
        table_block = display_df.to_markdown(index=False)
    except (ImportError, ModuleNotFoundError):  # pragma: no cover - fallback for minimal envs
        table_block = display_df.to_string(index=False)

    briefing_lines = ["# Strategic Lending Forecast Briefing", ""]

    briefing_lines.extend(["## Highlights", ""])
    for _, row in summary.iterrows():
        identifier = _format_identifier(row, identifier_cols)
        pieces: list[str] = []
        if "assets_mae_mean" in row:
            pieces.append(f"Assets MAE {_format_billions(row['assets_mae_mean'])}")
        if "equity_mae_mean" in row:
            pieces.append(f"Equity MAE {_format_billions(row['equity_mae_mean'])}")
        if "net_income_mae_mean" in row and not pd.isna(row["net_income_mae_mean"]):
            pieces.append(f"Net Income MAE {_format_billions(row['net_income_mae_mean'])}")
        if "identity_gap_mean" in row:
            pieces.append(
                f"Identity Gap {_format_billions(row['identity_gap_mean'])}"
            )

        coverage_fragments: list[str] = []
        coverage_warning = False
        for column, label in coverage_cols.items():
            value = row.get(column)
            if pd.isna(value):
                continue
            coverage_fragments.append(f"{label} {value:.2f}")
            if value < coverage_target:
                coverage_warning = True

        width_fragments: list[str] = []
        for column, label in width_cols.items():
            value = row.get(column)
            if pd.isna(value):
                continue
            width_fragments.append(
                f"{label} width {_format_billions(value)}"
            )

        if coverage_fragments:
            pieces.append("Coverage " + ", ".join(coverage_fragments))
        if width_fragments:
            pieces.append(
                "Interval span " + ", ".join(width_fragments)
            )

        identity_warning = False
        identity_value = row.get("identity_gap_mean")
        if identity_value is not None and not pd.isna(identity_value):
            if abs(float(identity_value)) > identity_threshold:
                identity_warning = True

        prefix = "- "
        if coverage_warning or identity_warning:
            prefix = "- ⚠️ "

        briefing_lines.append(prefix + f"**{identifier}**: " + "; ".join(pieces))

    briefing_lines.extend(["", "## Detailed Metrics", "", table_block, ""])
    return "\n".join(briefing_lines)


def main(argv: Sequence[str] | None = None) -> None:
    args = parse_args(argv)
    logging.basicConfig(level=getattr(logging, args.log_level.upper(), logging.INFO))

    group_cols = _parse_group_columns(args.group_by)

    if args.summary.exists():
        logging.info("Loading summary metrics from %s", args.summary)
        summary_df = pd.read_parquet(args.summary)
    else:
        logging.info("Summary not found; falling back to evaluation parquet %s", args.evaluation)
        if not args.evaluation.exists():
            raise FileNotFoundError(
                "Neither summary nor evaluation parquet could be located"
            )
        evaluation_df = pd.read_parquet(args.evaluation)
        if evaluation_df.empty:
            raise ValueError(
                "Evaluation parquet is empty; run evaluate_forecaster before generating the briefing"
            )
        summary_df = summarize_metrics(evaluation_df, group_cols)

    briefing = build_briefing(
        summary_df,
        group_cols,
        args.coverage_target,
        args.identity_threshold,
    )

    args.output.parent.mkdir(parents=True, exist_ok=True)
    args.output.write_text(briefing, encoding="utf-8")
    logging.info("Briefing written to %s", args.output)


if __name__ == "__main__":  # pragma: no cover
    main()

