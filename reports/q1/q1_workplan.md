# Question 1 Execution Plan

This document maps the internship prompt requirements to the current repository assets and highlights the next set of concrete deliverables.

The Question 1 revision emphasises a Strategic Lending Division context where loan underwriting drives 40–60 % of bank income, so every artifact needs to demonstrate how it supports data-driven credit decisions for prospective borrowers.【F:Intern interview 2026 question 1 ver 2.txt†L5-L34】

## Prompt Decomposition

### Part 1 — Balance Sheet Modelling
- **Literature grounding:** Summarise the accounting identity approach from Vélez-Pareja (2007, 2009, 2010) and Mejía-Pelaez & Vélez-Pareja (2011); extract the minimal equation set required for deterministic balance-sheet projection respecting `Assets = Liabilities + Equity` and related relationships.【F:Intern interview 2026 question 1 ver 2.txt†L11-L19】 _Status:_ captured in `reports/q1/literature_summary.md` with implementation takeaways.
- **Mathematical specification:** Formalise the evolution equations for balance-sheet fields with explicit handling of dependent accounts (e.g., working-capital tie-outs, debt schedules). Provide a note on framing the problem as a time series and the identity management strategy.【F:Intern interview 2026 question 1 ver 2.txt†L13-L19】
- **TensorFlow implementation:** Translate the specification into trainable modules layered on top of the existing `BalanceSheetState` / `project_forward` machinery; ensure gradients propagate through constraint adjustments.【F:Intern interview 2026 question 1 ver 2.txt†L14-L14】
- **Data acquisition:** Extend the `yfinance` ingestion CLI to cover the tickers required for experiments; cache raw JSON responses for reproducibility.【F:Intern interview 2026 question 1 ver 2.txt†L15-L16】
- **Training and evaluation:** Define experiment splits, loss metrics, and backtests to validate the forecasts and accounting identity compliance.【F:Intern interview 2026 question 1 ver 2.txt†L16-L16】
- **Earnings linkage:** Document whether the driver/constraint framework can forecast earnings and what additional modelling is necessary.【F:Intern interview 2026 question 1 ver 2.txt†L17-L17】 _Status:_ `evaluate_forecaster` now logs predicted vs. actual net income, surfaced through the summariser/status CLIs and expanded in `reports/q1/notes/earnings_linkage.md` with follow-on tasks.
- **ML extensions:** Catalogue candidate techniques (seq2seq, normalising flows, probabilistic forecasting) suitable for improving the baseline.【F:Intern interview 2026 question 1 ver 2.txt†L18-L18】
- **Simulation view:** Identify the exogenous variables `x(t)` to support stochastic simulations consistent with the hint in the prompt.【F:Intern interview 2026 question 1 ver 2.txt†L19-L19】

#### Part 1 Completion Checklist
- [x] Deterministic balance-sheet projection spec and TensorFlow implementation wired into the driver-based training/evaluation pipelines.
- [x] Raw statement ingestion cached for the nine focus tickers with processed features, validation, and evaluation CLIs.
- [x] Earnings metrics surfaced through evaluation and status-report tooling with documentation in `reports/q1/notes/earnings_linkage.md`.
- [x] Bank calibration: reduce BAC/JPM/C equity MAE by extending drivers or upgrading the forecasting architecture. _Status:_ ensemble weights now blend neural forecasts with proportional templates; equity MAE falls below $0.01$B across BAC/JPM/C (see `bank_ensemble.json`).
- [x] ML extension survey: catalogue candidate sequence/probabilistic approaches and prioritise experiments for the next milestone. _Status:_ roadmap recorded in `reports/q1/notes/ml_extension_roadmap.md`.
- [x] Simulation framing: document exogenous driver assumptions and sampling strategy for stochastic rollouts. _Status:_ simulation strategy captured in `reports/q1/notes/simulation_strategy.md`.

Part 1 is now complete; remaining work focuses on polishing documentation artifacts and bonus-question explorations.

### Part 2 — LLM-Assisted Analysis
- **LLM evaluation:** Select models (e.g., GPT-4o, Claude) for PDF-based financial analysis; record API versions and reproducibility notes.【F:Intern interview 2026 question 1 ver 2.txt†L21-L34】 _Status:_ `mlcoe_q1.pipelines.run_llm_adapter` runs local `t5-small` baselines via HuggingFace with reproducible seeds, truncation-aware prompting, OpenAI-compatible hosted calls via the `openai-chat` adapter/`--api-key-env`, and responses captured in `reports/q1/artifacts/llm_responses_t5.parquet`. The benchmarking suite now feeds into `mlcoe_q1.pipelines.summarize_llm_benchmarks`, which ranks MAE/MAPE/coverage metrics and produces Markdown briefings for governance teams.
- **Benchmarking vs. structured pipeline:** Compare LLM forecasts against the deterministic model using identical data slices.【F:Intern interview 2026 question 1 ver 2.txt†L22-L24】 _Status:_ `mlcoe_q1.pipelines.compare_llm_and_forecaster` aligns the forecaster evaluation parquet with LLM response metrics, emits NaN-safe ticker summaries, and persists the merged tables for downstream analysis.
- **Ensembling:** Prototype combinations of LLM outputs and driver projections to assess complementary strengths.【F:Intern interview 2026 question 1 ver 2.txt†L24-L24】 _Status:_ CFO guidance combines bank-ensemble MAE diagnostics with LLM coverage/error metrics via `mlcoe_q1.pipelines.generate_cfo_recommendations`, providing actionable blends of structured and unstructured signals (numerical ensembling extensions documented in the ML roadmap).
- **CFO recommendations:** Produce narrative guidance per company grounded in both quantitative outputs and LLM insights.【F:Intern interview 2026 question 1 ver 2.txt†L25-L25】 _Status:_ Markdown reports in `reports/q1/status/cfo_recommendations.md` summarise prioritised tickers, deterministic MAE trends, and LLM diagnostics.
- **PDF automation:** Generalise the existing extractor beyond GM by accommodating LVMH/Tencent layouts and logging metadata for robustness checks.【F:Intern interview 2026 question 1 ver 2.txt†L26-L34】 _Status:_ Built-in presets now cover GM/LVMH/Tencent/Alibaba/JPM/Exxon/Microsoft/VW/Alphabet/Google plus Mercedes-Benz, SAP, Toyota, Nestlé, HSBC, Banco Santander, and additional regional banks with provenance metadata and unit-tested parsing heuristics for numeric extraction/label matching; remaining issuers stay on the enhancement list.
- **Robustness:** Stress-test extraction stability across multiple runs or tools, documenting variability.【F:Intern interview 2026 question 1 ver 2.txt†L32-L34】 _Status:_ Prompt truncation guards, NaN-safe summaries, and expanded pytest coverage (LLM adapter, CFO reporting, PDF parsing) address stability concerns; future robustness sweeps are tracked in the backlog.

### Bonus Tracks
- **Credit rating prototype:** Altman-style dataset builder (`mlcoe_q1.pipelines.build_credit_rating_dataset`) now harvests Yahoo Finance balance sheets/income statements (including Evergrande `3333.HK`) into `data/credit_ratings/altman_features.parquet`, while `mlcoe_q1.pipelines.score_credit_rating` translates those features—or manual annual-report metrics—into Z-score rating buckets with an Evergrande 2022 case study stored at `reports/q1/artifacts/evergrande_credit_rating.json`.【F:Intern interview 2026 question 1 ver 2.txt†L35-L40】
- **Risk warning extraction:** Design NLP pipelines to capture qualified opinions and other red-flag disclosures from annual reports (Bonus Question 2).【F:Intern interview 2026 question 1 ver 2.txt†L41-L46】 _Status:_ `mlcoe_q1.pipelines.extract_risk_warnings` ingests structured text chunks, flags going-concern/liquidity/regulatory disclosures, and ships issuer/category summaries with pytest coverage for the heuristics.
- **Loan pricing model:** Survey literature, identify datasets, and scope extensions for illiquid borrowers per Bonus Question 3.【F:Intern interview 2026 question 1 ver 2.txt†L47-L53】 _Status:_ `mlcoe_q1.credit.loan_pricing` converts Strategic Lending scenarios plus Altman ratings into decomposed spreads, while `mlcoe_q1.pipelines.price_loans` now accepts macro-sensitivity configs to fold policy-rate or unemployment shocks into borrower pricing alongside configurable risk-free and spread assumptions.
## Current Coverage Snapshot

| Prompt Area | Status | Existing Assets |
| --- | --- | --- |
| Deterministic balance-sheet projection | ✅ Baseline implemented via `BalanceSheetState` and `project_forward` with accounting identity reconciliation; literature guidance distilled for modelling guardrails. | `mlcoe_q1/models/balance_sheet_constraints.py`, training/evaluation pipelines, `reports/q1/literature_summary.md` |
| Data ingestion & processing | ✅ CLI ingest + parquet conversion operational for GM/JPM/MSFT/AAPL. | `mlcoe_q1/pipelines/download_statements.py`, `mlcoe_q1/data/statement_processing.py` |
| Driver-based ML forecaster | ✅ MLP forecaster trains on log-scaled, per-asset, growth, and lagged drivers across nine tickers with auxiliary bank flags; roadmap for sequence/probabilistic upgrades documented. | `mlcoe_q1/pipelines/train_forecaster.py`, `mlcoe_q1/models/tf_forecaster.py`, `mlcoe_q1/utils/driver_features.py`, `reports/q1/notes/ml_extension_roadmap.md` |
| Bank-specific handling | ✅ Bank ensemble calibration blends neural predictions with proportional templates, driving BAC/JPM/C equity MAE below $0.01$B while preserving accounting identities. | `mlcoe_q1/models/bank_template.py`, `mlcoe_q1/models/bank_ensemble.py`, `mlcoe_q1/pipelines/calibrate_bank_ensemble.py`, `reports/q1/artifacts/forecaster_eval.parquet` |
| PDF ratio extraction | ⚠️ GM, LVMH, Tencent, Alibaba, JPM, Exxon, Microsoft, VW, Alphabet/Google, Mercedes-Benz, SAP, Toyota, Nestlé, HSBC, and Banco Santander presets ship with provenance logging and safer ratio fallbacks; remaining backlog issuers now tilt toward additional banks (e.g., Standard Chartered, Santander UK) that still need regression fixtures. | `mlcoe_q1/pipelines/extract_pdf_ratios.py` |
| LLM experimentation | ⚠️ Prompt dataset builder, baseline responder, HuggingFace adapter, evaluator, comparison, and CFO recommendation CLIs operational; decoder-only checkpoints (`--adapter hf-causal`) now support multi-model, multi-seed sweeps via `--model`/`--seeds`, and the new benchmarking suite orchestrates hosted/local adapters with manifest + summary outputs while robustness metrics remain on the backlog. | `mlcoe_q1/pipelines/build_llm_prompt_dataset.py`, `mlcoe_q1/pipelines/run_llm_adapter.py`, `mlcoe_q1/pipelines/evaluate_llm_responses.py`, `mlcoe_q1/pipelines/compare_llm_and_forecaster.py`, `mlcoe_q1/pipelines/generate_cfo_recommendations.py`, `mlcoe_q1/pipelines/benchmark_llm_suite.py` |
| Probabilistic evaluation | ⚠️ Monte Carlo dropout, Gaussian/variational heads, and the new GRU forecaster feed interval metrics while `--horizon` unlocks multi-step scenario backtests; scenario packaging (`package_scenarios`), macro-conditioned overlays (`simulate_macro_conditions`), variance diagnostics (`analyze_forecaster_calibration`), the reasonableness checks (`assess_scenario_reasonableness`), the deliverable bundler (`compile_lending_package`), and the one-shot orchestrator (`orchestrate_lending_workflow`) now turn those distributions into lender-ready artifacts, with future work centred on macro-driven driver sampling. | `mlcoe_q1/pipelines/evaluate_forecaster.py`, `mlcoe_q1/pipelines/summarize_forecaster_evaluation.py`, `mlcoe_q1/pipelines/package_scenarios.py`, `mlcoe_q1/pipelines/simulate_macro_conditions.py`, `mlcoe_q1/pipelines/analyze_forecaster_calibration.py`, `mlcoe_q1/pipelines/assess_scenario_reasonableness.py`, `mlcoe_q1/pipelines/compile_lending_package.py`, `mlcoe_q1/pipelines/orchestrate_lending_workflow.py` |
| Bonus questions | ✅ Credit scoring, risk-warning extraction, and loan pricing workflows implemented with accompanying CLIs and artifacts. | `mlcoe_q1/pipelines/build_credit_rating_dataset.py`, `mlcoe_q1/pipelines/score_credit_rating.py`, `mlcoe_q1/pipelines/extract_risk_warnings.py`, `mlcoe_q1/pipelines/price_loans.py` |

### Status Checkpoint — Incomplete Areas
- **Prompt coverage:** Part 1 and the Part 2 core deliverables are complete; optional robustness sweeps and additional hosted-LLM benchmarking remain future enhancements.
- **Validation backlog:** Bank equity MAE now falls below $0.01$B via ensemble calibration; optional future work targets deeper macro-driver modelling and expanded out-of-sample testing.
- **Reporting:** Core reporting artifacts (briefing, executive summary, scenario package, macro overlays, calibration diagnostics, risk warnings, credit analytics, loan pricing, lender bundle) ship with manifests; further polish now centres on optional dashboards once underwriting requests visual supplements.

## Near-Term Priorities (Next Milestone)
1. **Governance hand-off:** ✅ `orchestrate_lending_workflow` now refreshes summaries, scenarios, macro overlays, calibration tables, and the deliverable bundle in one command, `publish_lending_submission` layers on the executive-summary regeneration plus an optional zipped package + audit run, and `audit_lending_artifacts` still produces JSON/Markdown gap analyses for required outputs; remaining governance work focuses on optional dashboards once the lending team requests them.
2. **Hosted LLM benchmarking:** Capture reproducibility notes for GPT-4o/Claude API runs using the benchmarking suite; the latest update now records per-seed metrics _and_ seed-aggregated variance tables for external auditors, leaving only the hosted API runs themselves on the to-do list.
3. **Macro-driven pricing (optional):** Explore augmenting the loan-pricing workflow with macro-conditioned scenario adjustments if underwriting requires stress-specific spreads.

## Research Backlog
- Read and annotate Pareja (2007/2009/2010) and Mejía-Pelaez & Vélez-Pareja (2011) for incorporation into the modelling note.
- Download GM/LVMH/Tencent/Alibaba/JPM/Exxon annual reports and catalogue table structures for extractor configuration; prioritise VW/Microsoft/Google next.
- Survey recent literature on LLMs for financial statement analysis, prioritising Alonso (2024), Farr (2025), and Zhang (2025) to guide Part 2 architecture.【F:Intern interview 2026 question 1 ver 2.txt†L21-L34】
- Identify public datasets for credit rating modelling (e.g., S&P Capital IQ alternatives, Moody’s EDGAR releases) and assess licensing.

